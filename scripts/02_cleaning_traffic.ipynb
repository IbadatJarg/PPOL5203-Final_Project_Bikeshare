{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7dbe1c6",
   "metadata": {},
   "source": [
    "<h1><center> Data Cleaning File  <br><br> \n",
    "<font color='grey'> Cleaning Emissions and Traffic Data <br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c9ffd5",
   "metadata": {},
   "source": [
    "Traffic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7daf0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting library\n",
    "import requests\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa853685",
   "metadata": {},
   "outputs": [],
   "source": [
    "def traffic_query(coord_list):\n",
    "    \"\"\"\n",
    "    takes in a list of captial bikeshare coordinates\n",
    "    to tell API what data to retrieve\n",
    "    \"\"\"\n",
    "    \n",
    "    #extract coordinates\n",
    "    long = coord_list[0] #UPDATE LATER AFTER SEEING HOW IBADAT SET IT UP\n",
    "    lat = coord_list[1]\n",
    "    \n",
    "    #run query\n",
    "    B_URL = \"https://gis.mwcog.org/wa/rest/services/RTDC/Traffic_Counts_Annual/MapServer/0/query?\" #base url\n",
    "    \n",
    "    response = requests.get(\n",
    "        B_URL,\n",
    "        params = {\n",
    "            \"where\": \"1=1\", #no filters\n",
    "            \"outFields\": \"AADT2007,AADT2008,AADT2009,AADT2010,AADT2011,AADT2012,AADT2013,AADT2014,AADT2015,AADT2016,AADT2017,AADT2018,AADT2019\", #indicates which cols to return\n",
    "            \"geometry\": f\"{long},{lat}\", #input coordinates\n",
    "            \"geometryType\": \"esriGeometryPoint\", #indicates we're giving it points\n",
    "            \"distance\": 500, #how far away from point\n",
    "            \"units\": \"esriSRUnit_Meter\", #units in meters\n",
    "            \"inSR\": \"4326\", #coordiante system\n",
    "            \"f\": \"json\" #type of file to return\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    #check if successful\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        return \"Query Failed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cb1a7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_traffic(geo_json, item_len):\n",
    "    \"\"\"\n",
    "    function to extract columns of interest from traffic jsons\n",
    "    takes in the json created in traffic_query() as well as the length\n",
    "    of response.json()[\"features\"]\n",
    "    \"\"\"\n",
    "    #storing\n",
    "    temp = []\n",
    "    \n",
    "    #grabbing cols\n",
    "    for item in range(item_len):\n",
    "        obs = {\n",
    "                \"2007\": geo_json[\"features\"][item][\"attributes\"][\"AADT2007\"],\n",
    "                \"2008\": geo_json[\"features\"][item][\"attributes\"][\"AADT2008\"],\n",
    "                \"2009\": geo_json[\"features\"][item][\"attributes\"][\"AADT2009\"],\n",
    "                \"2010\": geo_json[\"features\"][item][\"attributes\"][\"AADT2010\"],\n",
    "                \"2011\": geo_json[\"features\"][item][\"attributes\"][\"AADT2011\"],\n",
    "                \"2012\": geo_json[\"features\"][item][\"attributes\"][\"AADT2012\"],\n",
    "                \"2013\": geo_json[\"features\"][item][\"attributes\"][\"AADT2013\"],\n",
    "                \"2014\": geo_json[\"features\"][item][\"attributes\"][\"AADT2014\"],\n",
    "                \"2015\": geo_json[\"features\"][item][\"attributes\"][\"AADT2015\"],\n",
    "                \"2016\": geo_json[\"features\"][item][\"attributes\"][\"AADT2016\"],\n",
    "                \"2017\": geo_json[\"features\"][item][\"attributes\"][\"AADT2017\"],\n",
    "                \"2018\": geo_json[\"features\"][item][\"attributes\"][\"AADT2018\"],\n",
    "                \"2019\": geo_json[\"features\"][item][\"attributes\"][\"AADT2019\"]\n",
    "            }\n",
    "        #appending to list\n",
    "        temp.append(obs)    \n",
    "        \n",
    "    #return \n",
    "    return(temp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f53da42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read open capital bikeshare file\n",
    "coord_df = pd.read_csv(\"../data/raw_data/opened_capital_bikes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52d4a205",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter for needed columns\n",
    "coord_df = coord_df.filter([\"STATION_ID\", \"LATITUDE\", \"LONGITUDE\", \"Opening Year\", \"Name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da4f2701",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns\n",
    "coord_df = coord_df.rename(columns = {\"STATION_ID\": \"cb_station\", \"LATITUDE\": \"lat\", \"LONGITUDE\": \"long\", \"Opening Year\": \"open_year\", \"Name\": \"name\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "813a5022",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create empty dataframe for storage\n",
    "traffic_df = pd.DataFrame(columns = ['id', 'long', 'lat', 'open_year', 'name',\n",
    "                                     '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dacb2a28",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\helen\\AppData\\Local\\Temp\\ipykernel_10024\\3130851139.py:38: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  traffic_df = pd.concat([traffic_df, test_df], ignore_index = True)\n",
      "C:\\Users\\helen\\AppData\\Local\\Temp\\ipykernel_10024\\3130851139.py:38: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  traffic_df = pd.concat([traffic_df, test_df], ignore_index = True)\n"
     ]
    }
   ],
   "source": [
    "#script to get average traffic volume for all opened capital bike shares\n",
    "for xy in range(len(coord_df)):\n",
    "    #runs query for coordinates\n",
    "    test_json = traffic_query([coord_df[\"long\"][xy], coord_df[\"lat\"][xy]])\n",
    "    \n",
    "    #adds if statement in case query fails or returns no coordinates\n",
    "    if test_json == \"Query Failed\" or len(test_json[\"features\"]) == 0:\n",
    "        #creates dataframe with NaN values for AADT\n",
    "        append = pd.DataFrame(columns = ['id', 'long', 'lat', 'open_year', 'name',\n",
    "                                     '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019'])\n",
    "        append.loc[len(append)] = np.nan\n",
    "        append['id'] = coord_df[\"cb_station\"][xy]\n",
    "        append['long'] = coord_df[\"long\"][xy]\n",
    "        append['lat'] = coord_df[\"lat\"][xy]\n",
    "        append['open_year'] = coord_df[\"open_year\"][xy]\n",
    "        append['name'] = coord_df[\"name\"][xy]\n",
    "        #append it to traffic_df\n",
    "        traffic_df = pd.concat([traffic_df, append], ignore_index = True)\n",
    "        continue\n",
    "        \n",
    "    #cleans up resulting json\n",
    "    test_clean = clean_traffic(test_json, len(test_json[\"features\"]))\n",
    "    #converts to pandas and filters for where there is data for both 2013 and 2019\n",
    "    test_df = pd.DataFrame(test_clean)\n",
    "\n",
    "    #gets mean traffic volume for all years\n",
    "    test_df = test_df.agg([\"mean\"]).reset_index(drop = True)\n",
    "\n",
    "    #adds station and search coordinates\n",
    "    test_df['id'] = coord_df[\"cb_station\"][xy]\n",
    "    test_df['long'] = coord_df[\"long\"][xy]\n",
    "    test_df['lat'] = coord_df[\"lat\"][xy]\n",
    "    test_df['open_year'] = coord_df[\"open_year\"][xy]\n",
    "    test_df['name'] = coord_df[\"name\"][xy]\n",
    "    #reorder cols to match storage dataframe\n",
    "    test_df = test_df[['id', 'long', 'lat', 'open_year', 'name','2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019']]\n",
    "    #add to storage dataframe\n",
    "    traffic_df = pd.concat([traffic_df, test_df], ignore_index = True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d084414",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#saving traffic data for opened capital bikes\n",
    "traffic_df.to_csv(\"../data/cleaned_data/opened_cb_traffic.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48c482d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading unopened capital bikeshare files (proposed bikeshares)\n",
    "unopened_df = pd.read_excel(\"../data/raw_data/unopened_capital_bikes_proposed.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d75bbf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter for needed columns\n",
    "unopened_df = unopened_df.filter([\"FID\", \"x\", \"y\", \"ClosestInt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e28f864b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns\n",
    "unopened_df = unopened_df.rename(columns = {\"FID\": \"cb_station\", \"y\": \"lat\", \"x\": \"long\", \"ClosestInt\": \"name\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8d61075",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create empty dataframe for storage\n",
    "unopened_traffic_df = pd.DataFrame(columns = ['id', 'long', 'lat', 'open_year', 'name',\n",
    "                                     '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2b67fe8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\helen\\AppData\\Local\\Temp\\ipykernel_10024\\2706135319.py:37: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  unopened_traffic_df = pd.concat([unopened_traffic_df, test_df], ignore_index = True)\n"
     ]
    }
   ],
   "source": [
    "#script to get average traffic volume for all unopened capital bike shares\n",
    "for xy in range(len(unopened_df)):\n",
    "    #runs query for coordinates\n",
    "    test_json = traffic_query([unopened_df[\"long\"][xy], unopened_df[\"lat\"][xy]])\n",
    "    \n",
    "    #adds if statement in case query fails or returns no coordinates\n",
    "    if test_json == \"Query Failed\" or len(test_json[\"features\"]) == 0:\n",
    "        #creates dataframe with NaN values for AADT\n",
    "        append = pd.DataFrame(columns = ['id', 'long', 'lat', 'open_year', 'name',\n",
    "                                     '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019'])\n",
    "        append.loc[len(append)] = np.nan\n",
    "        append['id'] = unopened_df[\"cb_station\"][xy]\n",
    "        append['long'] = unopened_df[\"long\"][xy]\n",
    "        append['lat'] = unopened_df[\"lat\"][xy]\n",
    "        append['name'] = unopened_df[\"name\"][xy]\n",
    "        #append it to traffic_df\n",
    "        unopened_traffic_df = pd.concat([unopened_traffic_df, append], ignore_index = True)\n",
    "        continue\n",
    "        \n",
    "    #cleans up resulting json\n",
    "    test_clean = clean_traffic(test_json, len(test_json[\"features\"]))\n",
    "    #converts to pandas and filters for where there is data for both 2013 and 2019\n",
    "    test_df = pd.DataFrame(test_clean)\n",
    "\n",
    "    #gets mean traffic volume for all years\n",
    "    test_df = test_df.agg([\"mean\"]).reset_index(drop = True)\n",
    "\n",
    "    #adds station and search coordinates\n",
    "    test_df['id'] = unopened_df[\"cb_station\"][xy]\n",
    "    test_df['long'] = unopened_df[\"long\"][xy]\n",
    "    test_df['lat'] = unopened_df[\"lat\"][xy]\n",
    "    test_df['open_year'] = np.nan\n",
    "    test_df['name'] = unopened_df[\"name\"][xy]\n",
    "    #reorder cols to match storage dataframe\n",
    "    test_df = test_df[['id', 'long', 'lat', 'open_year', 'name','2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019']]\n",
    "    #add to storage dataframe\n",
    "    unopened_traffic_df = pd.concat([unopened_traffic_df, test_df], ignore_index = True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e4d21c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving traffic data for unopened capital bikes\n",
    "unopened_traffic_df.to_csv(\"../data/cleaned_data/unopened_cb_traffic.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
